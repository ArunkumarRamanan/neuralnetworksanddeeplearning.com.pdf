\babel@toc {english}{}
\contentsline {chapter}{\numberline {1}Using neural nets to recognize handwritten digits}{1}{chapter.1}
\contentsline {section}{\numberline {1.1}Perceptrons}{2}{section.1.1}
\contentsline {section}{\numberline {1.2}Sigmoid neurons}{7}{section.1.2}
\contentsline {section}{\numberline {1.3}The architecture of neural networks}{10}{section.1.3}
\contentsline {section}{\numberline {1.4}A simple network to classify handwritten digits}{12}{section.1.4}
\contentsline {section}{\numberline {1.5}Learning with gradient descent}{15}{section.1.5}
\contentsline {section}{\numberline {1.6}Implementing our network to classify digits}{24}{section.1.6}
\contentsline {section}{\numberline {1.7}Toward deep learning}{33}{section.1.7}
\contentsline {chapter}{\numberline {2}How the backpropagation algorithm works}{37}{chapter.2}
\contentsline {section}{\numberline {2.1}Warm up: a fast matrix-based approach to computing the output from a neural network}{38}{section.2.1}
\contentsline {section}{\numberline {2.2}The two assumptions we need about the cost function}{40}{section.2.2}
\contentsline {section}{\numberline {2.3}The Hadamard product, $s\odot {}t$}{41}{section.2.3}
\contentsline {section}{\numberline {2.4}The four fundamental equations behind backpropagation}{41}{section.2.4}
\contentsline {section}{\numberline {2.5}Proof of the four fundamental equations (optional)}{45}{section.2.5}
\contentsline {section}{\numberline {2.6}The backpropagation algorithm}{47}{section.2.6}
\contentsline {subsection}{\numberline {2.6.1}Exercises}{47}{subsection.2.6.1}
\contentsline {section}{\numberline {2.7}The code for backpropagation}{48}{section.2.7}
\contentsline {section}{\numberline {2.8}In what sense is backpropagation a fast algorithm?}{50}{section.2.8}
\contentsline {section}{\numberline {2.9}Backpropagation: the big picture}{51}{section.2.9}
